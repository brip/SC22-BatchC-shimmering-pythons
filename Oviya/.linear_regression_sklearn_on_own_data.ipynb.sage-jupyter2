{"backend_state":"init","connection_file":"/projects/32f31ee3-50e6-4896-a9de-cba73af32175/.local/share/jupyter/runtime/kernel-29059540-bf7f-4475-af7f-b72ade394536.json","kernel":"python3-ubuntu","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"colab":{"collapsed_sections":[],"name":"linear_regression_sklearn_on_own_data.ipynb","provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"09a383","input":"sns.heatmap(my_data.corr())","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":344},"id":"H7FyJo_QutAX","outputId":"d1ad6159-df64-4882-e2ae-d78cfa814cc5"},"output":{"0":{"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f145260ae90>"},"exec_count":0,"output_type":"execute_result"},"1":{"data":{"image/png":"2608aca97f140c66d79a1201aa96d93a3a828437","text/plain":"<Figure size 432x288 with 2 Axes>"},"exec_count":0,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":9,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"18779b","input":"","pos":27,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"1cc4ed","input":"MAE = np.mean(abs(y_test - y_hat))\nMAE","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osxC5vVotKWS","outputId":"aa7e2d67-12af-4389-e7e0-4c23b23e8bf4"},"output":{"0":{"data":{"text/plain":"7.756195456791836"},"exec_count":0,"output_type":"execute_result"}},"pos":24,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"9cebe9","input":"#plotting results\nplt.figure(figsize=(10,5))\nplt.plot(x_test, y_hat, '--')\n\nplt.scatter(x_test,y_test, c='orange')  \nplt.xlabel('x', fontsize = 20) \nplt.ylabel('y', fontsize = 20)\nplt.title('Generated Data - Test')\nplt.grid('on')\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"id":"RarVj0Kor54b","outputId":"c3649dc9-e5f0-4930-f4b1-100ad0987777"},"output":{"0":{"data":{"image/png":"b183aad68e9d92822d562b2d62bac4ab20c205c4","text/plain":"<Figure size 720x360 with 1 Axes>"},"exec_count":0,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":21,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"e70e4f","input":"print(linr.score(x_test, y_test))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CS2KN6gms_io","outputId":"4f865d48-e1ea-4e80-ebb1-869f5f2052b0"},"output":{"0":{"name":"stdout","output_type":"stream","text":"0.5749959307112218\n"}},"pos":23,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"ec20f4","input":"#let's plot our split data to see how it looks!\nplt.figure(figsize=(10,5))\n\n# plot the train set \nplt.subplot(1,2,1)\nplt.scatter(x_train,y_train, c='orange')  \nplt.xlabel('x', fontsize = 20) \nplt.ylabel('y', fontsize = 20)\nplt.title('Generated Data - Train')\nplt.grid('on')\n\n# plot the test set \nplt.subplot(1,2,2)\nplt.scatter(x_test, y_test)  \nplt.xlabel('x', fontsize = 20) \nplt.ylabel('y', fontsize = 20)\nplt.title('Generated Data - Test')\nplt.grid('on')\n\nplt.show()","metadata":{"id":"6IxwdW5osUDI"},"output":{"0":{"data":{"image/png":"6a1a5fd8359f5605ec0335e3d11feb0335e81867","text/plain":"<Figure size 720x360 with 2 Axes>"},"exec_count":10,"metadata":{"image/png":{"height":342,"width":616},"needs_background":"light"},"output_type":"execute_result"}},"pos":16,"type":"cell"}
{"cell_type":"code","exec_count":11,"id":"de99b7","input":"from sklearn.linear_model import LinearRegression\n#Create the model object\nlinr = LinearRegression()\n#Fit (train) the model -- this is where the ML happens!\nlinr.fit(x_train, y_train)\nprint(linr.intercept_, linr.coef_[0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jkPf0bt4a-sV","outputId":"99433807-734f-4a07-fe0a-26b3ad2fb709"},"output":{"0":{"ename":"ValueError","evalue":"Input contains NaN, infinity or a value too large for dtype('float64').","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-4b90a63e84a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlinr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Fit (train) the model -- this is where the ML happens!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlinr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m    965\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    112\u001b[0m         ):\n\u001b[1;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"infinity\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"NaN, infinity\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."]}},"pos":18,"type":"cell"}
{"cell_type":"code","exec_count":12,"id":"4e0634","input":"# Predicting using SKLearn\ny_hat = linr.predict(x_test)","metadata":{"id":"o9ZDJB1qrJ7_"},"output":{"0":{"ename":"NotFittedError","evalue":"This LinearRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-2ee81a00c04e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predicting using SKLearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \"\"\"\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFittedError\u001b[0m: This LinearRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."]}},"pos":20,"type":"cell"}
{"cell_type":"code","exec_count":15,"id":"d461f8","input":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport statistics\n\nfilename = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/mpg.csv'\nmy_data = pd.read_csv(filename)\n\nmy_data.dropna(inplace = True)\nmy_data.drop_duplicates(inplace = True)\nmy_data = my_data.reset_index(drop=True)\n\nlength = len(my_data.index)\n\nX = my_data[\"horsepower\"].to_numpy()\ny = my_data[\"acceleration\"].to_numpy()\n\nif X.shape[0] != y.shape[0]:\n  print(\"It looks like you have missing data. You may want to preprocess your data more with pandas to delete any rows with missing, NaN, N/A, and null values.\")\n\nidx = np.arange(length)\nnp.random.shuffle(idx)\n\nsplit_threshold = int(length * 0.8)\n\ntrain_idx = idx[:split_threshold]\ntest_idx = idx[split_threshold:]\n\nx_train, y_train = X[train_idx], y[train_idx]\nx_test, y_test = X[test_idx], y[test_idx]\nx_train= x_train.reshape(-1, 1)\ny_train= y_train.reshape(-1, 1)\nx_test = x_test.reshape(-1, 1)\n\nfrom sklearn.linear_model import LinearRegression\n\nlinr = LinearRegression()\n\nlinr.fit(x_train, y_train)\nprint(linr.intercept_, linr.coef_[0])\n\ny_hat = linr.predict(x_test)\n\nplt.figure(figsize=(10,5))\nplt.plot(x_test, y_hat, '--')\n\nplt.scatter(x_test,y_test, c='black')\nplt.xlabel('x', fontsize = 20) \nplt.ylabel('y', fontsize = 20)\nplt.title('Generated Data - Test')\nplt.grid('on')\nplt.show()\nprediction = linr.score(x_test, y_test)\nprint(\"The prediction is:\", prediction)\nprint(\"\")\npredictionErr = np.mean(abs(y_test - y_hat))\nprint(\"The prediction error is: \", predicitonErr)\n\n\n\n\n\n\n","output":{"0":{"name":"stdout","output_type":"stream","text":"[20.50210121] [-0.0478522]\n"},"1":{"data":{"image/png":"bb5eb369aa7b3c2117b6a16199668ab5aab628a6","text/plain":"<Figure size 720x360 with 1 Axes>"},"exec_count":15,"metadata":{"image/png":{"height":342,"width":616},"needs_background":"light"},"output_type":"execute_result"},"2":{"name":"stdout","output_type":"stream","text":"The prediction is: 0.48314192360083075\n\n"},"3":{"ename":"NameError","evalue":"name 'predicitonErr' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-703a6c73d82d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mpredictionErr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The prediction error is: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicitonErr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'predicitonErr' is not defined"]}},"pos":26,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"b92704","input":"# import libraries \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport statistics","metadata":{"id":"IecuRdF1a-sG"},"pos":1,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"04953a","input":"filename = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/mpg.csv'\nmy_data = pd.read_csv(filename) #TODO: read in your file by replacing the filename variable with your file's path. You can also use this current code to work on an automobile dataset! ","metadata":{"id":"mBcweiAXW3bC"},"pos":5,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"bc840b","input":"my_data.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"2n8n7O_8cUxX","outputId":"b1d56a4f-9c74-4cf0-b1eb-055ea2aab14e"},"output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mpg</th>\n      <th>cylinders</th>\n      <th>displacement</th>\n      <th>horsepower</th>\n      <th>weight</th>\n      <th>acceleration</th>\n      <th>model_year</th>\n      <th>origin</th>\n      <th>name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18.0</td>\n      <td>8</td>\n      <td>307.0</td>\n      <td>130.0</td>\n      <td>3504</td>\n      <td>12.0</td>\n      <td>70</td>\n      <td>usa</td>\n      <td>chevrolet chevelle malibu</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15.0</td>\n      <td>8</td>\n      <td>350.0</td>\n      <td>165.0</td>\n      <td>3693</td>\n      <td>11.5</td>\n      <td>70</td>\n      <td>usa</td>\n      <td>buick skylark 320</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18.0</td>\n      <td>8</td>\n      <td>318.0</td>\n      <td>150.0</td>\n      <td>3436</td>\n      <td>11.0</td>\n      <td>70</td>\n      <td>usa</td>\n      <td>plymouth satellite</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16.0</td>\n      <td>8</td>\n      <td>304.0</td>\n      <td>150.0</td>\n      <td>3433</td>\n      <td>12.0</td>\n      <td>70</td>\n      <td>usa</td>\n      <td>amc rebel sst</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17.0</td>\n      <td>8</td>\n      <td>302.0</td>\n      <td>140.0</td>\n      <td>3449</td>\n      <td>10.5</td>\n      <td>70</td>\n      <td>usa</td>\n      <td>ford torino</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n0  18.0          8         307.0       130.0    3504          12.0   \n1  15.0          8         350.0       165.0    3693          11.5   \n2  18.0          8         318.0       150.0    3436          11.0   \n3  16.0          8         304.0       150.0    3433          12.0   \n4  17.0          8         302.0       140.0    3449          10.5   \n\n   model_year origin                       name  \n0          70    usa  chevrolet chevelle malibu  \n1          70    usa          buick skylark 320  \n2          70    usa         plymouth satellite  \n3          70    usa              amc rebel sst  \n4          70    usa                ford torino  "},"exec_count":5,"output_type":"execute_result"}},"pos":6,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"617c78","input":"X = my_data[\"horsepower\"].to_numpy()\ny = my_data[\"mpg\"].to_numpy()","metadata":{"id":"WW77IzOwZaKp"},"pos":11,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"b4ccd9","input":"#cleaning the data -- dropping missing and duplicate values for sanity\nmy_data.dropna(inplace = True)\nmy_data.drop_duplicates(inplace = True)\nmy_data = my_data.reset_index(drop=True)\n\nlength = len(my_data.index) #save length of array of later","metadata":{"id":"BYHvay0xa-sK"},"pos":7,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"40a40c","input":"# Checking for Missing Data\nif X.shape[0] != y.shape[0]:\n  print(\"It looks like you have missing data. You may want to preprocess your data more with pandas to delete any rows with missing, NaN, N/A, and null values.\")\n  \nidx = np.arange(length) #shuffle our dataset indices so we don't always split the same way!\nnp.random.shuffle(idx)\n\n#split our data with 80% for training (learning) and 20% for testing.\nsplit_threshold = int(length * 0.8)\n\ntrain_idx = idx[:split_threshold]\n# Uses the remaining indices for testing\ntest_idx = idx[split_threshold:]\n\n# Generates train and test sets and formats them for training.\nx_train, y_train = X[train_idx], y[train_idx]\nx_test, y_test = X[test_idx], y[test_idx]\nx_train= x_train.reshape(-1, 1)\ny_train= y_train.reshape(-1, 1)\nx_test = x_test.reshape(-1, 1)","metadata":{"id":"wKS4pvcEsLOF"},"pos":15,"type":"cell"}
{"cell_type":"markdown","id":"22dfb9","input":"### Creating Predictions\nPredict outputs on our x_test data that we held out. Think of this as a way to see how the model does on new data!","metadata":{"id":"QFb-_EiFrvzQ"},"pos":19,"type":"cell"}
{"cell_type":"markdown","id":"3f2472","input":"### Results and Evaluation\nOne way to see if the model is pretty good is the coefficient of determination (R^2) using the `score()` function. You can read about it here: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.score.\n\nAnother way is to compare our mean absolute error (MAE). MAE measures the prediction error. Mathematically, it is the average absolute difference between observed and predicted outcomes, MAE = mean(abs(observeds - predicteds)). MAE is less sensitive to outliers compared to RMSE.\n\nRead some more about regression model metrics [here](http://www.sthda.com/english/articles/38-regression-model-validation/158-regression-model-accuracy-metrics-r-square-aic-bic-cp-and-more/).","metadata":{"id":"14TdY4RGr-RG"},"pos":22,"type":"cell"}
{"cell_type":"markdown","id":"56d08e","input":"# Linear Regression with Scikit-learn's linear regression\n\nWe can use Scikit-Learnâ€™s Linear Regression to fit the model. Most other models we will use in the course \n\nhttps://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html","metadata":{"id":"cbeaQMpna-sR"},"pos":12,"type":"cell"}
{"cell_type":"markdown","id":"656abe","input":"Linear regression naturally works best on highly correlated data, so I'm going to create a heatmap to see which variables are correlated! ","metadata":{"id":"J3L_hb0Ou4sn"},"pos":8,"type":"cell"}
{"cell_type":"markdown","id":"7ad755","input":"Read in your data into a pandas dataframe by replacing the `filename` variable with your file's path. You can also use the current code below to work on a mpg dataset, where the target variable we are predicting is **miles per gallon** based on other car features. \n\n> We should choose two columns that we want to run regresssion on. Use the `.head()` function to decide which columns would be best!\n\n","metadata":{"id":"m4-2ySg9W0Fw"},"pos":3,"type":"cell"}
{"cell_type":"markdown","id":"7e1885","input":"# Data Loading, Cleaning, and Setup","metadata":{"id":"JlrQHpg8a-sI"},"pos":2,"type":"cell"}
{"cell_type":"markdown","id":"8a6c71","input":"### Getting to know the problem\n\nFor my data, my columns include `'mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', and 'name'`. \n\nTo start, I would like to create a linear regression model that uses horsepower (X) to predict miles per gallon (y) and see how strong our linear regression model is. For your data, you should choose two columns as well to represent X and y.\n\n","metadata":{"id":"w78dUshNZarz"},"pos":10,"type":"cell"}
{"cell_type":"markdown","id":"903f11","input":"np docs - https://numpy.org/doc/stable/reference/index.html#reference","pos":14,"type":"cell"}
{"cell_type":"markdown","id":"9e5d92","input":"pandas docs - https://pandas.pydata.org/docs/reference/index.html#api <br>\nseaborn docs - https://seaborn.pydata.org/api.html","pos":4,"type":"cell"}
{"cell_type":"markdown","id":"b5bbdd","input":"# Linear regression using SKLearn on your own Data!\nThis should look familiar... we now are going to use linear regression on some of our own features. I recommend walking through the code below first, then importing your dataset and working through the same problem with your data!","metadata":{"id":"K_X2fB9ta-rv"},"pos":0,"type":"cell"}
{"cell_type":"markdown","id":"d40fad","input":"### Split the data\nOur model should ignore 20% of data points to use for testing so it doesn't just memorize the data. We need to make sure there are no missing data points before continuing.","metadata":{"id":"g5Zk8_6ksLur"},"pos":13,"type":"cell"}
{"cell_type":"markdown","id":"d95313","input":"# Repeat the process!\n\nTry running linear regression on multiple combinations of features (columns) on your dataset. What combination yields the best score? How does this connect to your correlation chart? \n\n","metadata":{"id":"2OixzlOot-U6"},"pos":25,"type":"cell"}
{"cell_type":"markdown","id":"f9e2c8","input":"### Creating and Fitting","metadata":{"id":"e1m-wKeYsFEl"},"pos":17,"type":"cell"}
{"id":0,"time":1658944459985,"type":"user"}
{"last_load":1658958608753,"type":"file"}